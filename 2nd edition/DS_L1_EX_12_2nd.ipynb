{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS_L1_EX_12_2nd.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nullpitch-dev/DS_L1_Notebooks/blob/master/DS_L1_EX_12_2nd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR5lPnyWJgs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/nullpitch-dev/hj_public/master/baseball.csv'\n",
        "data = pd.read_csv(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cqWPZZeJQl2",
        "colab_type": "code",
        "outputId": "497251a2-61bb-42e8-fa16-df823de8a806",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# [1]\n",
        "\n",
        "# select 2015 and 2016 data\n",
        "data1 = data[(data.yearID == 2015) | (data.yearID == 2016)]\n",
        "\n",
        "# select moved player\n",
        "player = data1.groupby('playerID').agg({'teamID': 'nunique'})\n",
        "player = player.assign(moved=player.teamID.apply(lambda x: 1 if x == 2 else 0))\n",
        "player = player[player.moved == 1]\n",
        "\n",
        "# filter data with players in the moved players\n",
        "data1 = data1[data1.playerID.isin(player.index)]\n",
        "\n",
        "# filter data with AB > 400\n",
        "data1 = data1[data1.AB > 400]\n",
        "\n",
        "# both years' AB > 400 (year unique count should be 2)\n",
        "data1 = data1.groupby('playerID').agg({'yearID': 'nunique'})\n",
        "data1 = data1[data1.yearID == 2]\n",
        "\n",
        "# count players\n",
        "count = data1.count()\n",
        "\n",
        "print(f'Answer [1] : {count.iloc[0]}')"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer [1] : 17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z86w8FSuCCzp",
        "colab_type": "code",
        "outputId": "dae9ea79-6e95-45bd-bdb1-0aed8ff80ade",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# [2] corr\n",
        "\n",
        "# filter data with selected players\n",
        "data2 = data[data.playerID.isin(data1.index)][['playerID', 'yearID', 'H', 'AB',\n",
        "                                               'RBI', 'SH', 'SF']]\n",
        "\n",
        "# merge 2015 data and 2016 data in column\n",
        "data2015 = data2[data2.yearID == 2015]\n",
        "data2016 = data2[data2.yearID == 2016]\n",
        "data_con = pd.merge(data2015, data2016, how='inner', on='playerID',\n",
        "                    suffixes=('_15', '_16'))\n",
        "\n",
        "# create calculated columns\n",
        "data_con = data_con.assign(HR15=data_con.apply(lambda x: x.H_15 / x.AB_15,\n",
        "                                               axis=1))\n",
        "data_con = data_con.assign(SS15=data_con.apply(lambda x: x.SH_15 + x.SF_15,\n",
        "                                               axis=1))\n",
        "data_con = data_con.assign(RC16=data_con.apply(lambda x: x.RBI_16 / x.RBI_15,\n",
        "                                               axis=1))\n",
        "\n",
        "# corr\n",
        "corr1 = data_con[['HR15', 'RC16']].corr(method='pearson')\n",
        "corr2 = data_con[['SS15', 'RC16']].corr(method='pearson')\n",
        "\n",
        "print(f'Answer [2] : {corr1.RC16.iloc[0]:.2f}, {corr2.RC16.iloc[0]:.2f}')"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer [2] : -0.37, 0.42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31qFZmhUV0wj",
        "colab_type": "code",
        "outputId": "1e56e8a8-8a57-456d-daa2-cfdeac6af071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# [3] ttest_ind\n",
        "\n",
        "from scipy.stats import ttest_ind\n",
        "import math\n",
        "\n",
        "# calculate accumulated AB, debut year, mean RBI\n",
        "data3 = data.groupby('playerID').agg({'yearID': 'min', 'AB': 'sum',\n",
        "                                     'RBI': 'mean'})\n",
        "\n",
        "# filter by AB\n",
        "data3 = data3[data3.AB >= 200]\n",
        "\n",
        "# define group by debut year\n",
        "data3 = data3.assign(group=data3.yearID.apply(lambda x:\n",
        "                                              'A' if x < 2014 else 'B'))\n",
        "\n",
        "# perform T-test\n",
        "t_val, p_val = ttest_ind(data3[data3.group == 'A'].RBI,\n",
        "                         data3[data3.group == 'B'].RBI, equal_var=False)\n",
        "\n",
        "print(f'Answer [3] : {math.floor(p_val * 1000) / 1000}')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer [3] : 0.328\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmZb7Cljberl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb0b4958-43a6-43f1-dbdd-d4b545c1dc99"
      },
      "source": [
        "# [4] apriori, association_rules\n",
        "\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# collect unique teamID by playerID\n",
        "data4 = data.groupby('playerID').agg({'teamID': lambda x: list(set(x))})\n",
        "\n",
        "# filter by number of teamID >= 2\n",
        "data4 = data4.assign(cnt=data4.teamID.apply(lambda x: len(x)))\n",
        "data4 = data4[data4.cnt >= 2]\n",
        "\n",
        "# create teamID combination in list\n",
        "teams = list(data4.teamID)\n",
        "\n",
        "# convert data into pivot format\n",
        "te = TransactionEncoder()\n",
        "te_array = te.fit_transform(teams)\n",
        "te_df = pd.DataFrame(te_array, columns=te.columns_)\n",
        "\n",
        "# find frequent items with min support\n",
        "freq_items = apriori(te_df, min_support=0.0015, use_colnames=True)\n",
        "\n",
        "# perform association_rules\n",
        "asso = association_rules(freq_items, metric='confidence', min_threshold=0.5)\n",
        "\n",
        "# count number of rules\n",
        "cnt = len(asso.index)\n",
        "\n",
        "print(f'Answer [4] : {cnt}')"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer [4] : 65\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT2DxXmOb0HR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66171dd5-8910-4305-d8fd-99743f127a1e"
      },
      "source": [
        "# [5] rank, LogisticRegression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# filter by AB >= 400 and year >= 2014\n",
        "data5 = data[(data.AB >= 400) & (data.yearID >= 2014)]\n",
        "\n",
        "# mark top 30 tayul or not\n",
        "data5 = data5.assign(hitRate=data5.apply(lambda x: x.H / x.AB, axis=1))\n",
        "data5 = data5.assign(hitRank=data5.groupby('yearID').hitRate.rank(method='dense',\n",
        "                                                               ascending=False))\n",
        "                                      # in case of : 1 1st, 2 2nds, 1 3rd\n",
        "                                      # dense : 1, 2, 2, 3 \n",
        "                                      # min   : 1, 2, 2, 4\n",
        "                                      # max   : 1. 3, 3, 4\n",
        "data5 = data5.assign(top30=data5.hitRank.apply(lambda x: 1 if x <= 30 else 0))\n",
        "\n",
        "# insert 2 calculated columns\n",
        "data5 = data5.assign(GC=data5.apply(lambda x: x.HBP + x.BB, axis=1))\n",
        "data5 = data5.assign(JT=data5.apply(lambda x: (x.H + x.X2B + x.X3B * 2 +\n",
        "                                               x.HR * 3) / x.AB, axis=1))\n",
        "\n",
        "# mark if next year's top30 is 1 or not\n",
        "def getNextTop30(player, year):\n",
        "    nextYear = data5[(data5.playerID == player) & (data5.yearID == year + 1)]\n",
        "    if len(nextYear) != 0:\n",
        "        return nextYear.top30.iloc[0]\n",
        "\n",
        "data5 = data5.assign(target=data5.apply(lambda x:\n",
        "                                        getNextTop30(x.playerID, x.yearID),\n",
        "                                        axis=1))\n",
        "\n",
        "# prepare training and test set\n",
        "X_cols = ['RBI', 'GC', 'JT', 'SO']\n",
        "train = data5[data5.yearID == 2014].dropna()\n",
        "train_X = train[X_cols]\n",
        "train_y = train.target\n",
        "test = data5[data5.yearID == 2015].dropna()\n",
        "test_X = test[X_cols]\n",
        "test_y = test.target\n",
        "\n",
        "# train\n",
        "lr = LogisticRegression(C=100000, random_state=1234, penalty='l2',\n",
        "                        solver='newton-cg')\n",
        "model = lr.fit(train_X, train_y)\n",
        "\n",
        "# predict\n",
        "pred = model.predict_proba(test_X)\n",
        "pred_df = pd.DataFrame(pred, columns=['neg', 'pos'])\n",
        "pred_df = pred_df.assign(esti=pred_df.pos.apply(lambda x: 1 if x >= 0.18 else 0))\n",
        "\n",
        "# merget predict result with fact\n",
        "test_y = pd.DataFrame(test_y)\n",
        "test_y.reset_index(inplace=True)\n",
        "pred_df = pd.merge(pred_df, test_y, left_index=True, right_index=True)\n",
        "\n",
        "# find true positive\n",
        "pred_df = pred_df.assign(TP=pred_df.apply(lambda x: 1 if x.esti * x.target == 1\n",
        "                                                      else 0, axis=1))\n",
        "\n",
        "print(f'Answer [5] : {pred_df.TP.sum()}')"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer [5] : 21\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
