{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS_L1_EX_10_2nd.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nullpitch-dev/DS_L1_Notebooks/blob/master/DS_L1_EX_10_2nd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR5lPnyWJgs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/nullpitch-dev/hj_public/master/imdb.csv'\n",
        "data = pd.read_csv(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PU2FMtSMycNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [0]\n",
        "\n",
        "data = data.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc0ITEPRy_iK",
        "colab_type": "code",
        "outputId": "a7635ea7-db0b-4908-eae2-c4194bb6be9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# [1] ttest_ind\n",
        "\n",
        "from scipy import stats\n",
        "import math\n",
        "\n",
        "scifi_1 = data[data.SciFi == 1]\n",
        "scifi_0 = data[data.SciFi == 0]\n",
        "\n",
        "t_val, p_val = stats.ttest_ind(scifi_1.imdbRating, scifi_0.imdbRating,\n",
        "                               equal_var=False)\n",
        "\n",
        "print(f'Answer [1] : {math.floor(abs(t_val) * 1000) / 1000}')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer [1] : 9.792\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhVwVfC91fIn",
        "colab_type": "code",
        "outputId": "21646ea3-68a2-4f77-d565-bda7524b3502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# [2] KMeans, list comprehension, enumerate\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "\n",
        "# find years with more than 50 movies\n",
        "years = data.groupby('year').agg({'tid': 'count'})\n",
        "years = years[years.tid >= 50]\n",
        "\n",
        "# select movies in the years\n",
        "data2 = data[data.year.isin(years.index)]\n",
        "\n",
        "# create mean table\n",
        "mean = data2.groupby('year')['duration', 'imdbRating', 'nrOfGenre',\n",
        "                             'nrOfNewsArticles', 'nrOfUserReviews',\n",
        "                             'ratingCount'].mean()\n",
        "\n",
        "# Normalization\n",
        "norm = mean.apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
        "\n",
        "# KMeans\n",
        "cluster = KMeans(n_clusters=7, n_init=1234, random_state=1234).fit(norm)\n",
        "\n",
        "# find labels of 1977 \n",
        "label = cluster.labels_[np.where(norm.index == 1977)]\n",
        "\n",
        "# find years with the same label of 1977\n",
        "y_index = [i for i, v in enumerate(cluster.labels_) if v == label[0]]\n",
        "same_label_years = norm.index[y_index]\n",
        "\n",
        "# count all movies with same_label_years\n",
        "count = data2[data2.year.isin(same_label_years)].tid.count()\n",
        "\n",
        "print(f'Answer [2] : {count}')"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer [2] : 1047\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWGCy42JB8Lr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "76bb3fce-1beb-4e24-e1b6-2c6f0e9761aa"
      },
      "source": [
        "# [3] LogisticRegression, Odds ratio, list comprehension, enumerate\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "\n",
        "# select x variables\n",
        "X_cols = list(data.columns[2:4]) + list(data.columns[6:10])\n",
        "\n",
        "# create recommendation column\n",
        "data = data.assign(reco=data.imdbRating.apply(lambda x: 1 if x > 9 else 0))\n",
        "\n",
        "# prepare training set\n",
        "movie_X = data[data.type == 'video.movie'][X_cols]\n",
        "movie_y = data[data.type == 'video.movie'].reco\n",
        "episode_X = data[data.type == 'video.episode'][X_cols]\n",
        "episode_y = data[data.type == 'video.episode'].reco\n",
        "tv_X = data[data.type == 'video.tv'][X_cols]\n",
        "tv_y = data[data.type == 'video.tv'].reco\n",
        "\n",
        "# training\n",
        "lr_movie = LogisticRegression(C=100000, random_state=1234, penalty='l2',\n",
        "                              solver='newton-cg').fit(movie_X, movie_y)\n",
        "lr_episode = LogisticRegression(C=100000, random_state=1234, penalty='l2',\n",
        "                                solver='newton-cg').fit(episode_X, episode_y)\n",
        "lr_tv = LogisticRegression(C=100000, random_state=1234, penalty='l2',\n",
        "                           solver='newton-cg').fit(tv_X, tv_y)\n",
        "\n",
        "# find variable index with max Odds ratio (exp of coefficient)\n",
        "index_episode = [i for i, v in enumerate(np.exp(lr_episode.coef_)[0])\n",
        "                   if v == np.exp(lr_episode.coef_.max())]\n",
        "index_movie = [i for i, v in enumerate(np.exp(lr_movie.coef_)[0])\n",
        "                   if v == np.exp(lr_movie.coef_.max())]\n",
        "\n",
        "# find variable in the found index\n",
        "var_episode = X_cols[index_episode[0]]\n",
        "var_movie = X_cols[index_movie[0]]\n",
        "\n",
        "print(f'Answer [3] : {var_episode}, {var_movie}')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  \"number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  \"number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Answer [3] : nrOfUserReviews, ratingCount\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  \"number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sjb2HR0fyBkh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d72fec1-131f-4f01-d434-965b2f9e439f"
      },
      "source": [
        "# [4] apriori, association_rules\n",
        "\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "# include video.episode and exlcude nrOfGenre == 1\n",
        "data4 = data[data.type == 'video.episode']\n",
        "data4 = data4[data4.nrOfGenre != 1]\n",
        "\n",
        "# select genre columns\n",
        "cols = data4.columns[10:-1]\n",
        "\n",
        "# DataFrame is already in right format, no need TransactionEncoder\n",
        "frequent_items = apriori(data4[cols], min_support=0.01, use_colnames=True)\n",
        "asso = association_rules(frequent_items, metric='confidence',\n",
        "                         min_threshold=0.01)\n",
        "\n",
        "# select rules for 1 antecedent and 1 consequent\n",
        "asso = asso.assign(len_ant=asso.antecedents.apply(lambda x: len(x)))\n",
        "asso = asso.assign(len_con=asso.consequents.apply(lambda x: len(x)))\n",
        "asso = asso[(asso.len_ant == 1) & (asso.len_con == 1)]\n",
        "\n",
        "# find lowest lift item associated with Animation\n",
        "asso_ani = asso[asso.antecedents == {'Animation'}].sort_values(by='lift',\n",
        "                                                             ascending=True)\n",
        "lowlift = list(asso_ani.consequents.iloc[0])[0]\n",
        "\n",
        "# find confidence of lowlift over Animation\n",
        "confidence = asso_ani[asso_ani.consequents == {lowlift}].confidence.iloc[0]\n",
        "\n",
        "print(f'Answer [4] : {lowlift}, {confidence:.3f}')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer [4] : Drama, 0.062\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
