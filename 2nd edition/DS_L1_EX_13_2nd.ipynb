{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS_L1_EX_13_2nd.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nullpitch-dev/DS_L1_Notebooks/blob/master/DS_L1_EX_13_2nd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR5lPnyWJgs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/nullpitch-dev/hj_public/master/13.csv'\n",
        "data = pd.read_csv(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5k30DRNwgimg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# [0] drop_duplicate, sort_index(DONOT use sort_index), fillna\n",
        "\n",
        "# drop na for Year\n",
        "base = data.dropna(subset=['Year'])\n",
        "\n",
        "# drop duplicated year and keep latest\n",
        "base = base.sort_values(by=['Name', 'Platform', 'Year'],\n",
        "                        ascending=[True, True, True])\n",
        "base = base.drop_duplicates(subset=['Name', 'Platform'], keep='last')\n",
        "\n",
        "# replace na to 0\n",
        "targetCols = ['NA_Sales', 'EU_Sales', 'JP_Sales', 'Other_Sales'] \n",
        "base[targetCols] = base[targetCols].fillna(0)\n",
        "\n",
        "# add Global_sales\n",
        "base = base.assign(Global_sales=base[targetCols].sum(axis=1))\n",
        "\n",
        "# filter by platform with Global_sales >= 20000\n",
        "platforms = base.groupby('Platform').agg({'Global_sales': 'sum'})\n",
        "platforms = platforms[platforms.Global_sales >= 20000]\n",
        "base = base[base.Platform.isin(platforms.index)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm8KYOcoAx87",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5535b6c8-8507-44b1-d7e3-1cd29b7756bd"
      },
      "source": [
        "# [1] KNN, set_index\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# make check point type\n",
        "maxG = base.Global_sales.max()\n",
        "minG = base.Global_sales.min()\n",
        "medG = base.Global_sales.median()\n",
        "\n",
        "def check(x):\n",
        "    if (x == maxG) | (x == minG):\n",
        "        return 'Type1'\n",
        "    elif x == medG:\n",
        "        return 'type2'\n",
        "    else:\n",
        "        return 'Not Check Point'\n",
        "\n",
        "base = base.assign(check=base.Global_sales.apply(lambda x: check(x)))\n",
        "\n",
        "# perform KNN (train with Type1 and Type2, predict with all data)\n",
        "train_X = base[base.check != 'Not Check Point'][targetCols]\n",
        "train_y = base[base.check != 'Not Check Point'].check.to_numpy()\n",
        "knn = KNeighborsClassifier(n_neighbors=1).fit(train_X, train_y)\n",
        "\n",
        "# find closest point's Check Point Type\n",
        "test_X = base[targetCols]\n",
        "types = knn.predict(test_X)\n",
        "types = pd.DataFrame(types, columns=['outlier']) # convert to DataFrame\n",
        "base.reset_index(inplace=True) # reset index to match with knn result table\n",
        "base1 = pd.concat([base, types], axis=1) # merge knn result\n",
        "\n",
        "# remove outliers\n",
        "base1 = base1[base1.outlier != 'Type1']\n",
        "\n",
        "# calculate mean of Global_sales\n",
        "meanG = base1.Global_sales.mean()\n",
        "\n",
        "print(f'Answer [1] : {meanG:.3f}')\n",
        "\n",
        "# reindex with original index\n",
        "base1 = base1.set_index(keys='index')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer [1] : 74.201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfArBhxhhGgC",
        "colab_type": "code",
        "outputId": "efe774fc-9802-4704-b672-0d656599d789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# [2]\n",
        "\n",
        "# get number of unique Platforms per Name and Genre\n",
        "data2 = base1.groupby('Name').agg({'Platform': 'nunique', 'Genre': 'last'})\n",
        "\n",
        "# get average number of platforms per Genre\n",
        "data2 = data2.groupby('Genre').agg({'Platform': 'mean'})\n",
        "\n",
        "# get max and min Genre\n",
        "maxGenre = data2[data2.Platform == data2.Platform.max()].index[0]\n",
        "minGenre = data2[data2.Platform == data2.Platform.min()].index[0]\n",
        "\n",
        "print(f'Answer [2] : {maxGenre}, {minGenre}')"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer [2] : Action, Puzzle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8-5gmKbncX1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2e138067-9e88-450e-ba1d-6b287166c3d7"
      },
      "source": [
        "# [3] ttest_rel\n",
        "\n",
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# select games supporting both of PC and X360\n",
        "games = base1.groupby('Name').agg({'Platform': lambda x: list(set(x))})\n",
        "games = games.assign(contain=games.Platform.apply(lambda x:\n",
        "                                       1 if ('PC' in x) & ('X360' in x) else 0))\n",
        "games = games[games.contain == 1]\n",
        "\n",
        "# fiter data by Name in games\n",
        "data3 = base1[base1.Name.isin(games.index)]\n",
        "\n",
        "# perform ttest_ind\n",
        "t_val, p_val = ttest_rel(data3[data3.Platform == 'PC'].Global_sales,\n",
        "                         data3[data3.Platform == 'X360'].Global_sales)\n",
        "\n",
        "#\n",
        "print(f'Answer [3] : {abs(t_val):.3f}')"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer [3] : 7.772\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbjVgmek5ukr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "038f29b7-68be-4ebf-ce1a-0bf64093bc72"
      },
      "source": [
        "# [4] LogisticRegressioin, get_dummies\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# create dummy variables\n",
        "data4 = pd.get_dummies(base1, columns=['Platform'], drop_first=True)\n",
        "\n",
        "# create y value\n",
        "data4 = data4.assign(sports=data4.Genre.apply(lambda x: 1 if x == 'Sports'\n",
        "                                                          else 0))\n",
        "\n",
        "# set X variables\n",
        "X_cols = list(data4.columns[4:8]) + list(data4.columns[12:-1])\n",
        "\n",
        "# set train and test sets\n",
        "train_X = data4[data4.XGRP == 'A'][X_cols]\n",
        "train_y = data4[data4.XGRP == 'A'].sports\n",
        "test_X = data4[data4.XGRP == 'B'][X_cols]\n",
        "test_y = data4[data4.XGRP == 'B'].sports\n",
        "\n",
        "# train\n",
        "lr = LogisticRegression(C=100000, random_state=1234, penalty='l2',\n",
        "                        solver='newton-cg').fit(train_X, train_y)\n",
        "\n",
        "# predict\n",
        "pred = lr.predict_proba(test_X)\n",
        "pred_df = pd.DataFrame(pred, columns=['neg', 'pos']) # to DataFrame\n",
        "\n",
        "# calculate odds\n",
        "pred_df = pred_df.assign(odds=pred_df.pos.apply(lambda x: x / (1 - x)))\n",
        "\n",
        "# estimate\n",
        "pred_df = pred_df.assign(esti=pred_df.odds.apply(lambda x: 1 if x >= 0.12\n",
        "                                                             else 0))\n",
        "\n",
        "# merge estimate and facts\n",
        "test_y = pd.DataFrame(test_y).reset_index()\n",
        "pred_df = pd.merge(pred_df, test_y.sports, left_index=True, right_index=True)\n",
        "\n",
        "# calculate accuracy\n",
        "pred_df = pred_df.assign(true=pred_df.apply(lambda x: 1 if x.esti == x.sports\n",
        "                                                        else 0, axis=1))\n",
        "accuracy = pred_df.true.sum() / pred_df.true.count()\n",
        "\n",
        "print(f'Answer [4] : {accuracy:.3f}')"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Answer [4] : 0.383\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
